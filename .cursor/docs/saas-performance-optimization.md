# SAASå¹³å°æ€§èƒ½ä¼˜åŒ–ä¸éƒ¨ç½²

## ğŸš€ æ€§èƒ½ä¼˜åŒ–ä¸éƒ¨ç½²æ¶æ„

### æ€§èƒ½ä¼˜åŒ–ç­–ç•¥

#### 5.1 æ•°æ®åº“æ€§èƒ½ä¼˜åŒ–

**PostgreSQL ä¼˜åŒ–**

```sql
-- 1. ç´¢å¼•ä¼˜åŒ–
-- ç”¨æˆ·è¡¨ç´¢å¼•
CREATE INDEX idx_users_tenant_id ON users(tenant_id);
CREATE INDEX idx_users_organization_id ON users(organization_id);
CREATE INDEX idx_users_email ON users(email);
CREATE INDEX idx_users_username ON users(username);
CREATE INDEX idx_users_status ON users(status);
CREATE INDEX idx_users_created_at ON users(created_at);

-- ç»„ç»‡è¡¨ç´¢å¼•
CREATE INDEX idx_organizations_tenant_id ON organizations(tenant_id);
CREATE INDEX idx_organizations_parent_id ON organizations(parent_id);
CREATE INDEX idx_organizations_level ON organizations(level);
CREATE INDEX idx_organizations_status ON organizations(status);

-- éƒ¨é—¨è¡¨ç´¢å¼•
CREATE INDEX idx_departments_tenant_id ON departments(tenant_id);
CREATE INDEX idx_departments_organization_id ON departments(organization_id);
CREATE INDEX idx_departments_parent_id ON departments(parent_id);
CREATE INDEX idx_departments_level ON departments(level);

-- è§’è‰²è¡¨ç´¢å¼•
CREATE INDEX idx_roles_tenant_id ON roles(tenant_id);
CREATE INDEX idx_roles_status ON roles(status);

-- æƒé™è¡¨ç´¢å¼•
CREATE INDEX idx_permissions_tenant_id ON permissions(tenant_id);
CREATE INDEX idx_permissions_resource_action ON permissions(resource, action);

-- ç”¨æˆ·è§’è‰²å…³è”è¡¨ç´¢å¼•
CREATE INDEX idx_user_roles_user_id ON user_roles(user_id);
CREATE INDEX idx_user_roles_role_id ON user_roles(role_id);
CREATE INDEX idx_user_roles_tenant_id ON user_roles(tenant_id);

-- è§’è‰²æƒé™å…³è”è¡¨ç´¢å¼•
CREATE INDEX idx_role_permissions_role_id ON role_permissions(role_id);
CREATE INDEX idx_role_permissions_permission_id ON role_permissions(permission_id);

-- ä¼šè¯è¡¨ç´¢å¼•
CREATE INDEX idx_sessions_user_id ON sessions(user_id);
CREATE INDEX idx_sessions_tenant_id ON sessions(tenant_id);
CREATE INDEX idx_sessions_expires_at ON sessions(expires_at);
CREATE INDEX idx_sessions_status ON sessions(status);

-- é¢†åŸŸäº‹ä»¶è¡¨ç´¢å¼•
CREATE INDEX idx_domain_events_aggregate_id ON domain_events(aggregate_id);
CREATE INDEX idx_domain_events_event_type ON domain_events(event_type);
CREATE INDEX idx_domain_events_created_at ON domain_events(created_at);
CREATE INDEX idx_domain_events_tenant_id ON domain_events(tenant_id);

-- å®¡è®¡æ—¥å¿—è¡¨ç´¢å¼•
CREATE INDEX idx_audit_logs_user_id ON audit_logs(user_id);
CREATE INDEX idx_audit_logs_tenant_id ON audit_logs(tenant_id);
CREATE INDEX idx_audit_logs_action ON audit_logs(action);
CREATE INDEX idx_audit_logs_created_at ON audit_logs(created_at);

-- 2. åˆ†åŒºè¡¨ä¼˜åŒ–ï¼ˆé’ˆå¯¹å¤§æ•°æ®é‡ï¼‰
-- æŒ‰ç§Ÿæˆ·åˆ†åŒºçš„ç”¨æˆ·è¡¨
CREATE TABLE users_partitioned (
  id UUID PRIMARY KEY,
  tenant_id UUID NOT NULL,
  organization_id UUID,
  username VARCHAR(100) NOT NULL,
  email VARCHAR(255) NOT NULL,
  password_hash VARCHAR(255),
  status VARCHAR(20) DEFAULT 'active',
  last_login_at TIMESTAMP,
  created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
  updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
) PARTITION BY HASH (tenant_id);

-- åˆ›å»ºåˆ†åŒº
CREATE TABLE users_partition_0 PARTITION OF users_partitioned
FOR VALUES WITH (modulus 4, remainder 0);

CREATE TABLE users_partition_1 PARTITION OF users_partitioned
FOR VALUES WITH (modulus 4, remainder 1);

CREATE TABLE users_partition_2 PARTITION OF users_partitioned
FOR VALUES WITH (modulus 4, remainder 2);

CREATE TABLE users_partition_3 PARTITION OF users_partitioned
FOR VALUES WITH (modulus 4, remainder 3);

-- 3. æŸ¥è¯¢ä¼˜åŒ–
-- ä½¿ç”¨ CTE ä¼˜åŒ–å¤æ‚æŸ¥è¯¢
WITH user_permissions AS (
  SELECT
    u.id,
    u.username,
    u.email,
    u.tenant_id,
    u.organization_id,
    ARRAY_AGG(DISTINCT r.code) as roles,
    ARRAY_AGG(DISTINCT p.code) as permissions
  FROM users u
  LEFT JOIN user_roles ur ON u.id = ur.user_id
  LEFT JOIN roles r ON ur.role_id = r.id
  LEFT JOIN role_permissions rp ON r.id = rp.role_id
  LEFT JOIN permissions p ON rp.permission_id = p.id
  WHERE u.tenant_id = $1
  GROUP BY u.id, u.username, u.email, u.tenant_id, u.organization_id
)
SELECT * FROM user_permissions
WHERE organization_id = $2
ORDER BY username;

-- 4. è¿æ¥æ± é…ç½®
-- postgresql.conf ä¼˜åŒ–
max_connections = 200
shared_buffers = 256MB
effective_cache_size = 1GB
work_mem = 4MB
maintenance_work_mem = 64MB
checkpoint_completion_target = 0.9
wal_buffers = 16MB
default_statistics_target = 100
random_page_cost = 1.1
effective_io_concurrency = 200
```

**MongoDB ä¼˜åŒ–**

```typescript
// 1. ç´¢å¼•ä¼˜åŒ–
// ç”¨æˆ·è¯»æ¨¡å‹ç´¢å¼•
db.user_read_models.createIndex({ tenantId: 1 });
db.user_read_models.createIndex({ organizationId: 1 });
db.user_read_models.createIndex({ departmentIds: 1 });
db.user_read_models.createIndex({ username: 1 });
db.user_read_models.createIndex({ email: 1 });
db.user_read_models.createIndex({ status: 1 });
db.user_read_models.createIndex({ createdAt: -1 });

// å¤åˆç´¢å¼•
db.user_read_models.createIndex({ tenantId: 1, organizationId: 1 });
db.user_read_models.createIndex({ tenantId: 1, status: 1 });
db.user_read_models.createIndex({ tenantId: 1, createdAt: -1 });

// ç»„ç»‡è¯»æ¨¡å‹ç´¢å¼•
db.organization_read_models.createIndex({ tenantId: 1 });
db.organization_read_models.createIndex({ parentId: 1 });
db.organization_read_models.createIndex({ level: 1 });
db.organization_read_models.createIndex({ status: 1 });

// éƒ¨é—¨è¯»æ¨¡å‹ç´¢å¼•
db.department_read_models.createIndex({ tenantId: 1 });
db.department_read_models.createIndex({ organizationId: 1 });
db.department_read_models.createIndex({ parentId: 1 });
db.department_read_models.createIndex({ level: 1 });

// 2. èšåˆç®¡é“ä¼˜åŒ–
// ä¼˜åŒ–ç”¨æˆ·ç»Ÿè®¡æŸ¥è¯¢
db.user_read_models.aggregate([
  { $match: { tenantId: tenantId } },
  {
    $group: {
      _id: '$organizationId',
      userCount: { $sum: 1 },
      activeUsers: { $sum: { $cond: [{ $eq: ['$status', 'ACTIVE'] }, 1, 0] } },
      inactiveUsers: {
        $sum: { $cond: [{ $eq: ['$status', 'INACTIVE'] }, 1, 0] },
      },
    },
  },
  { $sort: { userCount: -1 } },
]);

// 3. åˆ†ç‰‡ç­–ç•¥ï¼ˆé’ˆå¯¹å¤§æ•°æ®é‡ï¼‰
// æŒ‰ç§Ÿæˆ·åˆ†ç‰‡
sh.shardCollection('saas.user_read_models', { tenantId: 1 });
sh.shardCollection('saas.organization_read_models', { tenantId: 1 });
sh.shardCollection('saas.department_read_models', { tenantId: 1 });

// 4. è¯»å†™å…³æ³¨çº§åˆ«ä¼˜åŒ–
// å†™æ“ä½œä½¿ç”¨ majority ç¡®ä¿æ•°æ®ä¸€è‡´æ€§
const writeOptions = { w: 'majority', j: true };

// è¯»æ“ä½œä½¿ç”¨ majority ç¡®ä¿è¯»å–æœ€æ–°æ•°æ®
const readOptions = { readConcern: { level: 'majority' } };

// 5. æ‰¹é‡æ“ä½œä¼˜åŒ–
// æ‰¹é‡æ’å…¥ç”¨æˆ·
const bulkOps = [];
users.forEach(user => {
  bulkOps.push({
    insertOne: {
      document: user,
    },
  });
});

if (bulkOps.length > 0) {
  await db
    .collection('user_read_models')
    .bulkWrite(bulkOps, { ordered: false });
}
```

#### 5.2 ç¼“å­˜ç­–ç•¥ä¼˜åŒ–

**Redis ç¼“å­˜ç­–ç•¥**

```typescript
// 1. ç¼“å­˜é”®å‘½åè§„èŒƒ
export class CacheKeyBuilder {
  // ç”¨æˆ·ç¼“å­˜é”®
  static userProfile(userId: string): string {
    return `user:profile:${userId}`;
  }

  static userPermissions(userId: string): string {
    return `user:permissions:${userId}`;
  }

  static userRoles(userId: string): string {
    return `user:roles:${userId}`;
  }

  // ç»„ç»‡ç¼“å­˜é”®
  static organizationProfile(orgId: string): string {
    return `org:profile:${orgId}`;
  }

  static organizationUsers(orgId: string): string {
    return `org:users:${orgId}`;
  }

  static organizationDepartments(orgId: string): string {
    return `org:departments:${orgId}`;
  }

  // éƒ¨é—¨ç¼“å­˜é”®
  static departmentProfile(deptId: string): string {
    return `dept:profile:${deptId}`;
  }

  static departmentUsers(deptId: string): string {
    return `dept:users:${deptId}`;
  }

  // æƒé™ç¼“å­˜é”®
  static rolePermissions(roleId: string): string {
    return `role:permissions:${roleId}`;
  }

  static userEffectivePermissions(userId: string): string {
    return `user:effective_permissions:${userId}`;
  }

  // ä¼šè¯ç¼“å­˜é”®
  static userSession(userId: string): string {
    return `session:user:${userId}`;
  }

  static sessionInfo(sessionId: string): string {
    return `session:info:${sessionId}`;
  }

  // æŸ¥è¯¢ç»“æœç¼“å­˜é”®
  static queryResult(queryHash: string): string {
    return `query:result:${queryHash}`;
  }

  // åˆ†é¡µç¼“å­˜é”®
  static paginatedResult(key: string, page: number, size: number): string {
    return `${key}:page:${page}:size:${size}`;
  }
}

// 2. ç¼“å­˜æœåŠ¡å®ç°
@Injectable()
export class CacheService {
  constructor(
    private readonly redis: Redis,
    private readonly logger: PinoLoggerService,
  ) {}

  // è®¾ç½®ç¼“å­˜
  async set(key: string, value: any, ttl?: number): Promise<void> {
    try {
      const serializedValue = JSON.stringify(value);
      if (ttl) {
        await this.redis.setex(key, ttl, serializedValue);
      } else {
        await this.redis.set(key, serializedValue);
      }
    } catch (error) {
      this.logger.error('Failed to set cache', { key, error: error.message });
    }
  }

  // è·å–ç¼“å­˜
  async get<T>(key: string): Promise<T | null> {
    try {
      const value = await this.redis.get(key);
      if (value) {
        return JSON.parse(value);
      }
      return null;
    } catch (error) {
      this.logger.error('Failed to get cache', { key, error: error.message });
      return null;
    }
  }

  // åˆ é™¤ç¼“å­˜
  async del(key: string): Promise<void> {
    try {
      await this.redis.del(key);
    } catch (error) {
      this.logger.error('Failed to delete cache', {
        key,
        error: error.message,
      });
    }
  }

  // æ‰¹é‡åˆ é™¤ç¼“å­˜
  async delPattern(pattern: string): Promise<void> {
    try {
      const keys = await this.redis.keys(pattern);
      if (keys.length > 0) {
        await this.redis.del(...keys);
      }
    } catch (error) {
      this.logger.error('Failed to delete cache pattern', {
        pattern,
        error: error.message,
      });
    }
  }

  // è®¾ç½®ç¼“å­˜å¹¶è®¾ç½®è¿‡æœŸæ—¶é—´
  async setex(key: string, ttl: number, value: any): Promise<void> {
    await this.set(key, value, ttl);
  }

  // æ£€æŸ¥é”®æ˜¯å¦å­˜åœ¨
  async exists(key: string): Promise<boolean> {
    try {
      const result = await this.redis.exists(key);
      return result === 1;
    } catch (error) {
      this.logger.error('Failed to check cache existence', {
        key,
        error: error.message,
      });
      return false;
    }
  }

  // è®¾ç½®ç¼“å­˜è¿‡æœŸæ—¶é—´
  async expire(key: string, ttl: number): Promise<void> {
    try {
      await this.redis.expire(key, ttl);
    } catch (error) {
      this.logger.error('Failed to set cache expiration', {
        key,
        ttl,
        error: error.message,
      });
    }
  }

  // è·å–ç¼“å­˜è¿‡æœŸæ—¶é—´
  async ttl(key: string): Promise<number> {
    try {
      return await this.redis.ttl(key);
    } catch (error) {
      this.logger.error('Failed to get cache TTL', {
        key,
        error: error.message,
      });
      return -1;
    }
  }
}

// 3. ç¼“å­˜è£…é¥°å™¨
export function Cacheable(key: string, ttl: number = 300) {
  return function (
    target: any,
    propertyName: string,
    descriptor: PropertyDescriptor,
  ) {
    const method = descriptor.value;

    descriptor.value = async function (...args: any[]) {
      const cacheService = this.cacheService;
      if (!cacheService) {
        return method.apply(this, args);
      }

      // æ„å»ºç¼“å­˜é”®
      const cacheKey = typeof key === 'function' ? key(...args) : key;

      // å°è¯•ä»ç¼“å­˜è·å–
      let result = await cacheService.get(cacheKey);
      if (result !== null) {
        return result;
      }

      // æ‰§è¡ŒåŸæ–¹æ³•
      result = await method.apply(this, args);

      // è®¾ç½®ç¼“å­˜
      if (result !== null && result !== undefined) {
        await cacheService.set(cacheKey, result, ttl);
      }

      return result;
    };
  };
}

// 4. ç¼“å­˜å¤±æ•ˆç­–ç•¥
export class CacheInvalidationService {
  constructor(
    private readonly cacheService: CacheService,
    private readonly logger: PinoLoggerService,
  ) {}

  // ç”¨æˆ·ç›¸å…³ç¼“å­˜å¤±æ•ˆ
  async invalidateUserCache(userId: string): Promise<void> {
    const patterns = [
      CacheKeyBuilder.userProfile(userId),
      CacheKeyBuilder.userPermissions(userId),
      CacheKeyBuilder.userRoles(userId),
      CacheKeyBuilder.userEffectivePermissions(userId),
      CacheKeyBuilder.userSession(userId),
    ];

    await this.invalidatePatterns(patterns);
  }

  // ç»„ç»‡ç›¸å…³ç¼“å­˜å¤±æ•ˆ
  async invalidateOrganizationCache(orgId: string): Promise<void> {
    const patterns = [
      CacheKeyBuilder.organizationProfile(orgId),
      CacheKeyBuilder.organizationUsers(orgId),
      CacheKeyBuilder.organizationDepartments(orgId),
    ];

    await this.invalidatePatterns(patterns);
  }

  // éƒ¨é—¨ç›¸å…³ç¼“å­˜å¤±æ•ˆ
  async invalidateDepartmentCache(deptId: string): Promise<void> {
    const patterns = [
      CacheKeyBuilder.departmentProfile(deptId),
      CacheKeyBuilder.departmentUsers(deptId),
    ];

    await this.invalidatePatterns(patterns);
  }

  // è§’è‰²æƒé™ç›¸å…³ç¼“å­˜å¤±æ•ˆ
  async invalidateRoleCache(roleId: string): Promise<void> {
    const patterns = [CacheKeyBuilder.rolePermissions(roleId)];

    await this.invalidatePatterns(patterns);
  }

  // æ‰¹é‡å¤±æ•ˆç¼“å­˜
  private async invalidatePatterns(patterns: string[]): Promise<void> {
    for (const pattern of patterns) {
      try {
        await this.cacheService.delPattern(pattern);
        this.logger.debug('Cache invalidated', { pattern });
      } catch (error) {
        this.logger.error('Failed to invalidate cache', {
          pattern,
          error: error.message,
        });
      }
    }
  }
}
```

#### 5.3 æŸ¥è¯¢æ€§èƒ½ä¼˜åŒ–

**GraphQL æŸ¥è¯¢ä¼˜åŒ–**

```typescript
// 1. æ•°æ®åŠ è½½å™¨ï¼ˆDataLoaderï¼‰å®ç°
@Injectable()
export class UserDataLoader {
  constructor(
    private readonly userService: UserService,
    private readonly cacheService: CacheService,
  ) {}

  // æ‰¹é‡åŠ è½½ç”¨æˆ·
  private userLoader = new DataLoader(async (userIds: string[]) => {
    const users = await this.userService.findByIds(userIds);
    const userMap = new Map(users.map(user => [user.id, user]));

    return userIds.map(id => userMap.get(id) || null);
  });

  // æ‰¹é‡åŠ è½½ç”¨æˆ·æƒé™
  private userPermissionsLoader = new DataLoader(async (userIds: string[]) => {
    const permissions = await this.userService.getUsersPermissions(userIds);
    const permissionMap = new Map(
      permissions.map(p => [p.userId, p.permissions]),
    );

    return userIds.map(id => permissionMap.get(id) || []);
  });

  // æ‰¹é‡åŠ è½½ç”¨æˆ·è§’è‰²
  private userRolesLoader = new DataLoader(async (userIds: string[]) => {
    const roles = await this.userService.getUsersRoles(userIds);
    const roleMap = new Map(roles.map(r => [r.userId, r.roles]));

    return userIds.map(id => roleMap.get(id) || []);
  });

  // è·å–ç”¨æˆ·
  async getUser(userId: string): Promise<User | null> {
    return this.userLoader.load(userId);
  }

  // è·å–ç”¨æˆ·æƒé™
  async getUserPermissions(userId: string): Promise<Permission[]> {
    return this.userPermissionsLoader.load(userId);
  }

  // è·å–ç”¨æˆ·è§’è‰²
  async getUserRoles(userId: string): Promise<Role[]> {
    return this.userRolesLoader.load(userId);
  }

  // æ¸…é™¤ç”¨æˆ·ç¼“å­˜
  clearUserCache(userId: string): void {
    this.userLoader.clear(userId);
    this.userPermissionsLoader.clear(userId);
    this.userRolesLoader.clear(userId);
  }
}

// 2. æŸ¥è¯¢å¤æ‚åº¦é™åˆ¶
export class QueryComplexityAnalyzer {
  private static readonly MAX_COMPLEXITY = 1000;
  private static readonly FIELD_WEIGHTS = {
    User: 1,
    Organization: 2,
    Department: 2,
    Role: 1,
    Permission: 1,
    Tenant: 1,
  };

  static analyzeQuery(query: string, variables?: any): number {
    let complexity = 0;

    // è§£ææŸ¥è¯¢å¤æ‚åº¦
    const ast = parse(query);
    const visitor = new QueryComplexityVisitor();
    visit(ast, visitor);

    complexity = visitor.getComplexity();

    if (complexity > this.MAX_COMPLEXITY) {
      throw new Error(
        `Query complexity ${complexity} exceeds maximum ${this.MAX_COMPLEXITY}`,
      );
    }

    return complexity;
  }
}

// 3. æŸ¥è¯¢ç»“æœç¼“å­˜
@Injectable()
export class QueryCacheService {
  constructor(
    private readonly cacheService: CacheService,
    private readonly logger: PinoLoggerService,
  ) {}

  // ç¼“å­˜æŸ¥è¯¢ç»“æœ
  async cacheQueryResult(
    query: string,
    variables: any,
    result: any,
    ttl: number = 300,
  ): Promise<void> {
    try {
      const queryHash = this.generateQueryHash(query, variables);
      const cacheKey = CacheKeyBuilder.queryResult(queryHash);

      await this.cacheService.set(
        cacheKey,
        {
          result,
          timestamp: Date.now(),
          ttl,
        },
        ttl,
      );
    } catch (error) {
      this.logger.error('Failed to cache query result', {
        error: error.message,
      });
    }
  }

  // è·å–ç¼“å­˜çš„æŸ¥è¯¢ç»“æœ
  async getCachedQueryResult(
    query: string,
    variables: any,
  ): Promise<any | null> {
    try {
      const queryHash = this.generateQueryHash(query, variables);
      const cacheKey = CacheKeyBuilder.queryResult(queryHash);

      const cached = await this.cacheService.get(cacheKey);
      if (cached && Date.now() - cached.timestamp < cached.ttl * 1000) {
        return cached.result;
      }

      return null;
    } catch (error) {
      this.logger.error('Failed to get cached query result', {
        error: error.message,
      });
      return null;
    }
  }

  // ç”ŸæˆæŸ¥è¯¢å“ˆå¸Œ
  private generateQueryHash(query: string, variables: any): string {
    const queryString = JSON.stringify({ query, variables });
    return createHash('sha256').update(queryString).digest('hex');
  }
}

// 4. åˆ†é¡µæŸ¥è¯¢ä¼˜åŒ–
export class PaginationOptimizer {
  // æ¸¸æ ‡åˆ†é¡µå®ç°
  static createCursorPagination<T>(
    items: T[],
    pageSize: number,
    cursor?: string,
  ): CursorPaginationResult<T> {
    if (items.length === 0) {
      return {
        edges: [],
        pageInfo: {
          hasNextPage: false,
          hasPreviousPage: false,
          startCursor: null,
          endCursor: null,
        },
      };
    }

    const edges = items.map(item => ({
      node: item,
      cursor: Buffer.from(
        JSON.stringify({ id: item.id, timestamp: item.createdAt }),
      ).toString('base64'),
    }));

    const pageInfo = {
      hasNextPage: items.length === pageSize,
      hasPreviousPage: !!cursor,
      startCursor: edges[0]?.cursor || null,
      endCursor: edges[edges.length - 1]?.cursor || null,
    };

    return { edges, pageInfo };
  }

  // åç§»åˆ†é¡µå®ç°
  static createOffsetPagination<T>(
    items: T[],
    total: number,
    page: number,
    size: number,
  ): OffsetPaginationResult<T> {
    const totalPages = Math.ceil(total / size);

    return {
      data: items,
      pagination: {
        page,
        size,
        total,
        totalPages,
        hasNext: page < totalPages,
        hasPrev: page > 1,
      },
    };
  }
}
```

### éƒ¨ç½²æ¶æ„

#### 5.4 å®¹å™¨åŒ–éƒ¨ç½²

**Docker é…ç½®**

```dockerfile
# å¤šé˜¶æ®µæ„å»º Dockerfile
FROM node:18-alpine AS base

# å®‰è£… pnpm
RUN npm install -g pnpm

# è®¾ç½®å·¥ä½œç›®å½•
WORKDIR /app

# å¤åˆ¶ package.json å’Œ pnpm-lock.yaml
COPY package.json pnpm-lock.yaml ./

# å®‰è£…ä¾èµ–
RUN pnpm install --frozen-lockfile

# æ„å»ºé˜¶æ®µ
FROM base AS builder

# å¤åˆ¶æºä»£ç 
COPY . .

# æ„å»ºåº”ç”¨
RUN pnpm run build

# ç”Ÿäº§é˜¶æ®µ
FROM node:18-alpine AS production

# å®‰è£… dumb-init ç”¨äºè¿›ç¨‹ç®¡ç†
RUN apk add --no-cache dumb-init

# åˆ›å»ºé root ç”¨æˆ·
RUN addgroup -g 1001 -S nodejs
RUN adduser -S nestjs -u 1001

# è®¾ç½®å·¥ä½œç›®å½•
WORKDIR /app

# å¤åˆ¶æ„å»ºäº§ç‰©
COPY --from=builder --chown=nestjs:nodejs /app/dist ./dist
COPY --from=builder --chown=nestjs:nodejs /app/node_modules ./node_modules
COPY --from=builder --chown=nestjs:nodejs /app/package.json ./

# åˆ‡æ¢åˆ°é root ç”¨æˆ·
USER nestjs

# æš´éœ²ç«¯å£
EXPOSE 3000

# å¥åº·æ£€æŸ¥
HEALTHCHECK --interval=30s --timeout=3s --start-period=5s --retries=3 \
  CMD node dist/health-check.js

# å¯åŠ¨åº”ç”¨
ENTRYPOINT ["dumb-init", "--"]
CMD ["node", "dist/main.js"]
```

**Docker Compose é…ç½®**

```yaml
# docker-compose.yml
version: '3.8'

services:
  # ä¸»åº”ç”¨æœåŠ¡
  app:
    build: .
    container_name: saas-app
    restart: unless-stopped
    ports:
      - '3000:3000'
    environment:
      - NODE_ENV=production
      - DATABASE_URL=postgresql://postgres:password@postgres:5432/saas
      - MONGODB_URL=mongodb://mongodb:27017/saas
      - REDIS_URL=redis://redis:6379
      - JWT_SECRET=your-jwt-secret
      - JWT_EXPIRES_IN=24h
    depends_on:
      - postgres
      - mongodb
      - redis
    networks:
      - saas-network
    volumes:
      - ./logs:/app/logs
      - ./uploads:/app/uploads

  # PostgreSQL æ•°æ®åº“
  postgres:
    image: postgres:15-alpine
    container_name: saas-postgres
    restart: unless-stopped
    environment:
      - POSTGRES_DB=saas
      - POSTGRES_USER=postgres
      - POSTGRES_PASSWORD=password
    ports:
      - '5432:5432'
    volumes:
      - postgres_data:/var/lib/postgresql/data
      - ./init-scripts:/docker-entrypoint-initdb.d
    networks:
      - saas-network
    command: >
      postgres
      -c max_connections=200
      -c shared_buffers=256MB
      -c effective_cache_size=1GB
      -c work_mem=4MB
      -c maintenance_work_mem=64MB
      -c checkpoint_completion_target=0.9
      -c wal_buffers=16MB
      -c default_statistics_target=100
      -c random_page_cost=1.1
      -c effective_io_concurrency=200

  # MongoDB æ•°æ®åº“
  mongodb:
    image: mongo:7.0
    container_name: saas-mongodb
    restart: unless-stopped
    environment:
      - MONGO_INITDB_DATABASE=saas
    ports:
      - '27017:27017'
    volumes:
      - mongodb_data:/data/db
      - ./mongo-init:/docker-entrypoint-initdb.d
    networks:
      - saas-network
    command: >
      mongod
      --wiredTigerCacheSizeGB 1
      --maxInMemorySortGB 1
      --setParameter maxTransactionLockRequestTimeoutMillis=5000

  # Redis ç¼“å­˜
  redis:
    image: redis:7-alpine
    container_name: saas-redis
    restart: unless-stopped
    ports:
      - '6379:6379'
    volumes:
      - redis_data:/data
      - ./redis.conf:/usr/local/etc/redis/redis.conf
    networks:
      - saas-network
    command: redis-server /usr/local/etc/redis/redis.conf

  # Nginx åå‘ä»£ç†
  nginx:
    image: nginx:alpine
    container_name: saas-nginx
    restart: unless-stopped
    ports:
      - '80:80'
      - '443:443'
    volumes:
      - ./nginx/nginx.conf:/etc/nginx/nginx.conf
      - ./nginx/conf.d:/etc/nginx/conf.d
      - ./ssl:/etc/nginx/ssl
      - ./logs/nginx:/var/log/nginx
    depends_on:
      - app
    networks:
      - saas-network

  # ç›‘æ§æœåŠ¡
  prometheus:
    image: prom/prometheus:latest
    container_name: saas-prometheus
    restart: unless-stopped
    ports:
      - '9090:9090'
    volumes:
      - ./monitoring/prometheus.yml:/etc/prometheus/prometheus.yml
      - prometheus_data:/prometheus
    networks:
      - saas-network
    command: >
      --config.file=/etc/prometheus/prometheus.yml
      --storage.tsdb.path=/prometheus
      --web.console.libraries=/etc/prometheus/console_libraries
      --web.console.templates=/etc/prometheus/consoles
      --storage.tsdb.retention.time=200h
      --web.enable-lifecycle

  # Grafana ç›‘æ§é¢æ¿
  grafana:
    image: grafana/grafana:latest
    container_name: saas-grafana
    restart: unless-stopped
    ports:
      - '3001:3000'
    environment:
      - GF_SECURITY_ADMIN_PASSWORD=admin
    volumes:
      - grafana_data:/var/lib/grafana
      - ./monitoring/grafana/provisioning:/etc/grafana/provisioning
    networks:
      - saas-network

volumes:
  postgres_data:
  mongodb_data:
  redis_data:
  prometheus_data:
  grafana_data:

networks:
  saas-network:
    driver: bridge
```

#### 5.5 è´Ÿè½½å‡è¡¡ä¸é«˜å¯ç”¨

**Nginx é…ç½®**

```nginx
# nginx/nginx.conf
user nginx;
worker_processes auto;
error_log /var/log/nginx/error.log warn;
pid /var/run/nginx.pid;

events {
    worker_connections 1024;
    use epoll;
    multi_accept on;
}

http {
    include /etc/nginx/mime.types;
    default_type application/octet-stream;

    # æ—¥å¿—æ ¼å¼
    log_format main '$remote_addr - $remote_user [$time_local] "$request" '
                    '$status $body_bytes_sent "$http_referer" '
                    '"$http_user_agent" "$http_x_forwarded_for"';

    access_log /var/log/nginx/access.log main;

    # åŸºç¡€é…ç½®
    sendfile on;
    tcp_nopush on;
    tcp_nodelay on;
    keepalive_timeout 65;
    types_hash_max_size 2048;
    client_max_body_size 100M;

    # Gzip å‹ç¼©
    gzip on;
    gzip_vary on;
    gzip_min_length 1024;
    gzip_proxied any;
    gzip_comp_level 6;
    gzip_types
        text/plain
        text/css
        text/xml
        text/javascript
        application/json
        application/javascript
        application/xml+rss
        application/atom+xml
        image/svg+xml;

    # ä¸Šæ¸¸æœåŠ¡å™¨é…ç½®
    upstream app_servers {
        least_conn;
        server app:3000 max_fails=3 fail_timeout=30s;
        # å¯ä»¥æ·»åŠ æ›´å¤šåº”ç”¨å®ä¾‹
        # server app2:3000 max_fails=3 fail_timeout=30s;
        # server app3:3000 max_fails=3 fail_timeout=30s;
    }

    # é™æµé…ç½®
    limit_req_zone $binary_remote_addr zone=api:10m rate=10r/s;
    limit_req_zone $binary_remote_addr zone=login:10m rate=5r/m;

    # ä¸»æœåŠ¡å™¨é…ç½®
    server {
        listen 80;
        server_name localhost;
        return 301 https://$server_name$request_uri;
    }

    server {
        listen 443 ssl http2;
        server_name localhost;

        # SSL é…ç½®
        ssl_certificate /etc/nginx/ssl/cert.pem;
        ssl_certificate_key /etc/nginx/ssl/key.pem;
        ssl_protocols TLSv1.2 TLSv1.3;
        ssl_ciphers ECDHE-RSA-AES128-GCM-SHA256:ECDHE-RSA-AES256-GCM-SHA384;
        ssl_prefer_server_ciphers off;
        ssl_session_cache shared:SSL:10m;
        ssl_session_timeout 10m;

        # å®‰å…¨å¤´
        add_header X-Frame-Options DENY;
        add_header X-Content-Type-Options nosniff;
        add_header X-XSS-Protection "1; mode=block";
        add_header Strict-Transport-Security "max-age=31536000; includeSubDomains" always;

        # å®¢æˆ·ç«¯é…ç½®
        client_max_body_size 100M;
        client_body_timeout 60s;
        client_header_timeout 60s;

        # ä»£ç†é…ç½®
        proxy_http_version 1.1;
        proxy_set_header Upgrade $http_upgrade;
        proxy_set_header Connection 'upgrade';
        proxy_set_header Host $host;
        proxy_set_header X-Real-IP $remote_addr;
        proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;
        proxy_set_header X-Forwarded-Proto $scheme;
        proxy_cache_bypass $http_upgrade;
        proxy_read_timeout 300s;
        proxy_connect_timeout 75s;
        proxy_send_timeout 300s;

        # å¥åº·æ£€æŸ¥
        location /health {
            access_log off;
            return 200 "healthy\n";
            add_header Content-Type text/plain;
        }

        # API é™æµ
        location /api/ {
            limit_req zone=api burst=20 nodelay;

            proxy_pass http://app_servers;
            proxy_set_header Host $host;
            proxy_set_header X-Real-IP $remote_addr;
            proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;
            proxy_set_header X-Forwarded-Proto $scheme;
        }

        # ç™»å½•æ¥å£é™æµ
        location /api/auth/login {
            limit_req zone=login burst=5 nodelay;

            proxy_pass http://app_servers;
            proxy_set_header Host $host;
            proxy_set_header X-Real-IP $remote_addr;
            proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;
            proxy_set_header X-Forwarded-Proto $scheme;
        }

        # GraphQL æ¥å£
        location /graphql {
            limit_req zone=api burst=20 nodelay;

            proxy_pass http://app_servers;
            proxy_set_header Host $host;
            proxy_set_header X-Real-IP $remote_addr;
            proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;
            proxy_set_header X-Forwarded-Proto $scheme;
        }

        # é™æ€æ–‡ä»¶
        location /static/ {
            expires 1y;
            add_header Cache-Control "public, immutable";
            proxy_pass http://app_servers;
        }

        # é»˜è®¤ä»£ç†
        location / {
            proxy_pass http://app_servers;
            proxy_set_header Host $host;
            proxy_set_header X-Real-IP $remote_addr;
            proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;
            proxy_set_header X-Forwarded-Proto $scheme;
        }
    }
}
```

#### 5.6 ç›‘æ§ä¸æ—¥å¿—

**Prometheus é…ç½®**

```yaml
# monitoring/prometheus.yml
global:
  scrape_interval: 15s
  evaluation_interval: 15s

rule_files:
  - 'rules/*.yml'

scrape_configs:
  - job_name: 'saas-app'
    static_configs:
      - targets: ['app:3000']
    metrics_path: '/metrics'
    scrape_interval: 10s

  - job_name: 'postgres'
    static_configs:
      - targets: ['postgres:5432']
    metrics_path: '/metrics'
    scrape_interval: 30s

  - job_name: 'mongodb'
    static_configs:
      - targets: ['mongodb:27017']
    metrics_path: '/metrics'
    scrape_interval: 30s

  - job_name: 'redis'
    static_configs:
      - targets: ['redis:6379']
    metrics_path: '/metrics'
    scrape_interval: 30s

  - job_name: 'nginx'
    static_configs:
      - targets: ['nginx:80']
    metrics_path: '/nginx_status'
    scrape_interval: 30s
```

**åº”ç”¨ç›‘æ§æŒ‡æ ‡**

```typescript
// åº”ç”¨ç›‘æ§æŒ‡æ ‡
import { Injectable } from '@nestjs/common';
import { register, Counter, Histogram, Gauge } from 'prom-client';

@Injectable()
export class MetricsService {
  // HTTP è¯·æ±‚è®¡æ•°å™¨
  private httpRequestsTotal = new Counter({
    name: 'http_requests_total',
    help: 'Total number of HTTP requests',
    labelNames: ['method', 'route', 'status_code'],
  });

  // HTTP è¯·æ±‚æŒç»­æ—¶é—´
  private httpRequestDuration = new Histogram({
    name: 'http_request_duration_seconds',
    help: 'HTTP request duration in seconds',
    labelNames: ['method', 'route'],
    buckets: [0.1, 0.5, 1, 2, 5],
  });

  // æ´»è·ƒè¿æ¥æ•°
  private activeConnections = new Gauge({
    name: 'active_connections',
    help: 'Number of active connections',
  });

  // æ•°æ®åº“æŸ¥è¯¢è®¡æ•°å™¨
  private databaseQueriesTotal = new Counter({
    name: 'database_queries_total',
    help: 'Total number of database queries',
    labelNames: ['database', 'operation'],
  });

  // æ•°æ®åº“æŸ¥è¯¢æŒç»­æ—¶é—´
  private databaseQueryDuration = new Histogram({
    name: 'database_query_duration_seconds',
    help: 'Database query duration in seconds',
    labelNames: ['database', 'operation'],
    buckets: [0.01, 0.05, 0.1, 0.5, 1, 2, 5],
  });

  // ç¼“å­˜å‘½ä¸­ç‡
  private cacheHits = new Counter({
    name: 'cache_hits_total',
    help: 'Total number of cache hits',
  });

  private cacheMisses = new Counter({
    name: 'cache_misses_total',
    help: 'Total number of cache misses',
  });

  // ä¸šåŠ¡æŒ‡æ ‡
  private activeUsers = new Gauge({
    name: 'active_users',
    help: 'Number of active users',
    labelNames: ['tenant_id'],
  });

  private totalUsers = new Gauge({
    name: 'total_users',
    help: 'Total number of users',
    labelNames: ['tenant_id'],
  });

  // è®°å½• HTTP è¯·æ±‚
  recordHttpRequest(
    method: string,
    route: string,
    statusCode: number,
    duration: number,
  ): void {
    this.httpRequestsTotal.inc({ method, route, status_code: statusCode });
    this.httpRequestDuration.observe({ method, route }, duration);
  }

  // è®°å½•æ•°æ®åº“æŸ¥è¯¢
  recordDatabaseQuery(
    database: string,
    operation: string,
    duration: number,
  ): void {
    this.databaseQueriesTotal.inc({ database, operation });
    this.databaseQueryDuration.observe({ database, operation }, duration);
  }

  // è®°å½•ç¼“å­˜å‘½ä¸­
  recordCacheHit(): void {
    this.cacheHits.inc();
  }

  // è®°å½•ç¼“å­˜æœªå‘½ä¸­
  recordCacheMiss(): void {
    this.cacheMisses.inc();
  }

  // æ›´æ–°æ´»è·ƒç”¨æˆ·æ•°
  updateActiveUsers(tenantId: string, count: number): void {
    this.activeUsers.set({ tenant_id: tenantId }, count);
  }

  // æ›´æ–°æ€»ç”¨æˆ·æ•°
  updateTotalUsers(tenantId: string, count: number): void {
    this.totalUsers.set({ tenant_id: tenantId }, count);
  }

  // è·å–æŒ‡æ ‡
  getMetrics(): string {
    return register.metrics();
  }
}
```

**æ—¥å¿—é…ç½®**

```typescript
// æ—¥å¿—é…ç½®
import { LoggerService } from '@nestjs/common';
import { PinoLoggerService } from '@aiofix/logging';

@Injectable()
export class LoggingService implements LoggerService {
  constructor(private readonly pinoLogger: PinoLoggerService) {}

  log(message: any, context?: string): void {
    this.pinoLogger.info(message, { context });
  }

  error(message: any, trace?: string, context?: string): void {
    this.pinoLogger.error(message, { trace, context });
  }

  warn(message: any, context?: string): void {
    this.pinoLogger.warn(message, { context });
  }

  debug(message: any, context?: string): void {
    this.pinoLogger.debug(message, { context });
  }

  verbose(message: any, context?: string): void {
    this.pinoLogger.trace(message, { context });
  }
}

// æ—¥å¿—ä¸­é—´ä»¶
@Injectable()
export class LoggingMiddleware implements NestMiddleware {
  constructor(private readonly logger: LoggingService) {}

  use(req: Request, res: Response, next: NextFunction): void {
    const startTime = Date.now();
    const { method, url, headers, body } = req;

    // è®°å½•è¯·æ±‚å¼€å§‹
    this.logger.log(`Request started: ${method} ${url}`, 'HTTP');

    // å“åº”å®Œæˆåçš„æ—¥å¿—è®°å½•
    res.on('finish', () => {
      const duration = Date.now() - startTime;
      const { statusCode } = res;

      this.logger.log(
        `Request completed: ${method} ${url} - ${statusCode} (${duration}ms)`,
        'HTTP',
      );

      // è®°å½•æ…¢è¯·æ±‚
      if (duration > 1000) {
        this.logger.warn(
          `Slow request detected: ${method} ${url} - ${duration}ms`,
          'HTTP',
        );
      }

      // è®°å½•é”™è¯¯è¯·æ±‚
      if (statusCode >= 400) {
        this.logger.error(
          `Request failed: ${method} ${url} - ${statusCode}`,
          undefined,
          'HTTP',
        );
      }
    });

    next();
  }
}
```

---

**æ–‡æ¡£ç‰ˆæœ¬**: v1.0.0  
**åˆ›å»ºæ—¥æœŸ**: 2024-12-19  
**é€‚ç”¨èŒƒå›´**: SAASå¹³å°æ€§èƒ½ä¼˜åŒ–ä¸éƒ¨ç½²æŒ‡å¯¼
